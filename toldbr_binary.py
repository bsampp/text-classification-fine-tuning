# -*- coding: utf-8 -*-
"""toldbr-binary.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fbOQZHFRFNcgzd2szAE54X0051lqwte4
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install wandb
!wandb login

!pip install torch
!pip install transformers[torch] datasets

import os
os.environ["WANDB_PROJECT"]="toldbr-bertimbau-final"

from transformers import AutoModelForSequenceClassification
from datasets import load_dataset, ClassLabel, concatenate_datasets

ds = load_dataset("JAugusto97/told-br", "binary")

ds = ds.shuffle(seed=42)

train_ds = concatenate_datasets([ds["train"], ds["validation"]])
test_ds = ds["test"]
train_ds[3]

# Load model directly
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)
#tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')

from sklearn.metrics import accuracy_score, precision_recall_fscore_support
import numpy as np
def compute_metrics(p):
    # Extract the logits and the labels
    logits, labels = p
    predictions = np.argmax(logits, axis=-1)

    # Compute the accuracy
    accuracy = accuracy_score(labels, predictions)

    # Compute precision, recall, and F1 score
    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')

    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
    }

tokenize = lambda sentences: tokenizer(sentences['text'], \
                                      truncation=True,
                                       padding='max_length',
                                       max_length=128)

tok_train_ds = train_ds.map(tokenize, batched=True)
tok_test_ds = test_ds.map(tokenize, batched=True)

import tempfile
from sklearn.model_selection import KFold
temp_output_dir = tempfile.mkdtemp()

from transformers import Trainer, TrainingArguments, DataCollatorWithPadding

batch_size = 16

num_folds = 5

kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)

checkpoint_dir = os.path.join(temp_output_dir, "checkpoints")

accuracies = []
f1_scores = []
precision_scores = []
recall_scores = []


train_losses = []
val_losses = []

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

def get_training_args(fold_num):
    output_dir = os.path.join(checkpoint_dir, f"fold_{fold_num}")
    return TrainingArguments(
        output_dir=output_dir,
        #num_train_epochs=2,
        #per_device_train_batch_size=32,
        #per_device_eval_batch_size=32,
        #warmup_steps=500,
        #weight_decay=0.01,
        logging_steps=10,
        save_steps=500,
        save_total_limit=3,
        load_best_model_at_end=True,
        eval_strategy="steps",
        eval_steps=500,
        report_to="wandb",
        run_name=f"bert-base-default-fold-{fold_num}"
    )

import numpy as np
import os
from time import time
import wandb
checkpoint_dir = "./model_checkpoints"

best_model_path = ""
best_val_loss = float('inf')

for fold_num, (train_index, val_index) in enumerate(kf.split(np.arange(len(tok_train_ds)))):
    fold_output_dir = os.path.join(checkpoint_dir, f"fold_{fold_num}")
    os.makedirs(fold_output_dir, exist_ok=True)

    model = AutoModelForSequenceClassification.from_pretrained("neuralmind/bert-base-portuguese-cased", num_labels=2)
    #model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=2)
    train_fold = tok_train_ds.select(train_index)
    val_fold = tok_train_ds.select(val_index)

    trainer = Trainer(
        model=model,
        args=get_training_args(fold_num),
        train_dataset=train_fold,
        eval_dataset=val_fold,
        compute_metrics=compute_metrics,
        data_collator=data_collator,
    )

    print(f"Fold {fold_num + 1}")
    start_time = time()

    checkpoint_path = os.path.join(fold_output_dir, "checkpoint-xxxx")

    if os.path.exists(checkpoint_path):
        trainer.train(resume_from_checkpoint=checkpoint_path)
    else:
        print(f"Checkpoint not found at {checkpoint_path}. Starting training from scratch.")
        trainer.train()

    end_time = time()
    training_time = end_time - start_time
    wandb.log({"fold": fold_num, "training_time": training_time})
    print(f"Training time for fold {fold_num + 1}: {training_time} seconds")

    result = trainer.evaluate()

    accuracy = result["eval_accuracy"]
    f1 = result["eval_f1"]
    precision = result["eval_precision"]
    recall = result["eval_recall"]
    val_loss = result["eval_loss"]

    print(f"Accuracy: {accuracy}")
    print(f"Precision: {precision}")
    print(f"Recall: {recall}")
    print(f"F1: {f1}")
    print(f"Val Loss: {val_loss}")

    accuracies.append(accuracy)
    f1_scores.append(f1)
    precision_scores.append(precision)
    recall_scores.append(recall)
    val_losses.append(val_loss)

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        best_model_path = trainer.state.best_model_checkpoint

print(f"Best model path: {best_model_path}")

mean_accuracy = np.mean(accuracies)
mean_f1 = np.mean(f1_scores)
mean_precision = np.mean(precision_scores)
mean_recall = np.mean(recall_scores)
mean_val_loss = np.mean(val_losses)

print(f"Mean accuracy: {mean_accuracy}")
print(f"Mean F1 score: {mean_f1}")
print(f"Mean precision: {mean_precision}")
print(f"Mean recall: {mean_recall}")
print(f"Mean val loss: {mean_val_loss}")

# Carregando e avaliando o melhor modelo no conjunto de teste
best_model = AutoModelForSequenceClassification.from_pretrained(best_model_path)
trainer = Trainer(
    model=best_model,
    args=get_training_args(0),  # Os argumentos são irrelevantes para a avaliação
    compute_metrics=compute_metrics,
    data_collator=data_collator,
)

test_result = trainer.evaluate(eval_dataset=tok_test_ds)
test_accuracy = test_result["eval_accuracy"]
test_f1 = test_result["eval_f1"]
test_precision = test_result["eval_precision"]
test_recall = test_result["eval_recall"]

print(f"Test Accuracy: {test_accuracy}")
print(f"Test F1: {test_f1}")
print(f"Test Precision: {test_precision}")
print(f"Test Recall: {test_recall}")

import torch
input_text = "eu te amo "

inputs = tokenizer(input_text, return_tensors="pt", padding=True, truncation=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
inputs = {k: v.to(device) for k, v in inputs.items()}

model.eval()

with torch.no_grad():
    outputs = model(**inputs)

logits = outputs.logits

probabilities = torch.nn.functional.softmax(logits, dim=-1)

predicted_class_idx = torch.argmax(probabilities, dim=1).item()

class_labels = ['Classe 0', 'Classe 1']

predicted_class_label = class_labels[predicted_class_idx]

# Exiba o resultado
print(f"Text: {input_text}")
print(f"Predicted Class: {predicted_class_label} (Índice: {predicted_class_idx})")
print(f"Probabilities: {probabilities}")

wandb.finish()